---
title: "Dual Verification Results"
author: "Pierce Edmiston"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
---

```{r, echo = FALSE, message = FALSE}
library(knitr)

opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.path = 'results-figs/'
)

read_chunk("models/overall.R")
read_chunk("models/proposition.R")
read_chunk("models/picture.R")
read_chunk("models/rts.R")

library(dplyr)
library(ggplot2)
library(lme4)
library(broom)

devtools::load_all("dualverification")
dualverification <- compile("experiment/data/") %>%
  clean %>% 
  recode %>%
  # Combine feat_type and mask_type for colors in the plot
  mutate(feat_mask = paste(feat_type, mask_type, sep = ":"))
```

# Overall results

```{r, overall-plot}
```

# Answer proposition (replication)

It doesn't look like we are replicating the `feat_type:mask_type` interation.
There is a huge main effect, such that errors on visual knowledge questions
were significantly more likely. Based on the results of Experiment 2 we would
have expected error rates on the blank screen trials to be equivalent. I don't
have a good explanation for why error rates on the nomask trials would be
so much higher in this experiment.

```{r, proposition-mod, echo = 1}
```

```{r, proposition-plot}
```

# Verify picture

```{r, pic-mod, echo = 1}
```

```{r, pic-plot}
```

# Reaction times

The picture task took longer than the proposition task, which was surprising
to me until I remembered that pictures only appeared on 25% of the trials,
so they are probably slower because they were rare.

A frustrating finding is that the mask made people faster across the board. It
seems that the offset of the mask is a more salient trigger for when to expect
the onset of the response window than the perceived offset of the auditory cue,
even though the length of the trial depends on the length of the auditory cues,
i.e., the mask is not shown for the same duration on every trial. The offset of
the mask is exactly contingent on the offset of the cue.

There aren't any main effects of knowledge type in either task. I know we can't
run with a null effect, but it is nice to know that there is no evidence in 
RTs to support the hypothesis that the visual questions are just harder.

```{r, overall-rts-mod, echo = 1}
```

```{r, overall-rts-plot}
```

## Reaction times to answer propositions

```{r, proposition-rts-mod, echo = 1}
```

```{r, proposition-rts-plot}
```

## Reaction times to verify pictures

```{r, picture-rts-mod, echo = 1}
```

```{r, picture-rts-plot}
```
